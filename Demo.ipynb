{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfh8vTVvX3Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBwI5blFf3zz",
        "colab_type": "text"
      },
      "source": [
        "# UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E7JdIAGk9Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMGvqHIPX6dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm']\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    \"\"\"Checks if a file is an image.\n",
        "\n",
        "    Args:\n",
        "        filename (string): path to a file\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the filename ends with a known image extension\n",
        "    \"\"\"\n",
        "    filename_lower = filename.lower()\n",
        "    return any(filename_lower.endswith(ext) for ext in IMG_EXTENSIONS)\n",
        "\n",
        "\n",
        "def find_classes(dir, classes_idx=None):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    classes.sort()\n",
        "    if classes_idx is not None:\n",
        "        assert type(classes_idx) == tuple\n",
        "        start, end = classes_idx\n",
        "        classes = classes[start:end]\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "\n",
        "def make_dataset(dir, class_to_idx):\n",
        "    images = []\n",
        "    dir = os.path.expanduser(dir)\n",
        "    for target in sorted(os.listdir(dir)):\n",
        "        if target not in class_to_idx:\n",
        "            continue\n",
        "        d = os.path.join(dir, target)\n",
        "        if not os.path.isdir(d):\n",
        "            continue\n",
        "\n",
        "        for root, _, fnames in sorted(os.walk(d)):\n",
        "            for fname in sorted(fnames):\n",
        "                if is_image_file(fname):\n",
        "                    path = os.path.join(root, fname)\n",
        "                    item = (path, class_to_idx[target])\n",
        "                    images.append(item)\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        with Image.open(f) as img:\n",
        "            return img.convert('RGB')\n",
        "\n",
        "\n",
        "def accimage_loader(path):\n",
        "    import accimage\n",
        "    try:\n",
        "        return accimage.Image(path)\n",
        "    except IOError:\n",
        "        # Potentially a decoding problem, fall back to PIL.Image\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "    if get_image_backend() == 'accimage':\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "class ImageFolder(data.Dataset):\n",
        "    \"\"\"A generic data loader where the images are arranged in this way: ::\n",
        "\n",
        "        root/dog/xxx.png\n",
        "        root/dog/xxy.png\n",
        "        root/dog/xxz.png\n",
        "\n",
        "        root/cat/123.png\n",
        "        root/cat/nsdf3.png\n",
        "        root/cat/asd932_.png\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory path.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        loader (callable, optional): A function to load an image given its path.\n",
        "\n",
        "     Attributes:\n",
        "        classes (list): List of the class names.\n",
        "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
        "        imgs (list): List of (image path, class_index) tuples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root, transform=None, target_transform=None,\n",
        "                 loader=default_loader, classes_idx=None):\n",
        "        self.classes_idx = classes_idx\n",
        "        classes, class_to_idx = find_classes(root, self.classes_idx)\n",
        "        imgs = make_dataset(root, class_to_idx)\n",
        "        if len(imgs) == 0:\n",
        "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
        "                               \"Supported image extensions are: \" + \",\".join(IMG_EXTENSIONS)))\n",
        "\n",
        "        self.root = root\n",
        "        self.imgs = imgs\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is class_index of the target class.\n",
        "        \"\"\"\n",
        "        path, target = self.imgs[index]\n",
        "        img = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a5V120EX6fe",
        "colab_type": "code",
        "outputId": "7c928bb5-0865-4c71-bf12-3b63e3966b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os.path\n",
        "import sys\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from six.moves import urllib\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import scipy.misc\n",
        "import math\n",
        "import sys\n",
        "\n",
        "import glob\n",
        "#filelist = glob.glob('/content/drive/My Drive/cs236/fakes/10platent/10pfakes/*.png')\n",
        "#filelist = glob.glob('/content/drive/My Drive/cs236/fakes/fakesis/10p400/*.png')\n",
        "#filelist = glob.glob('/content/drive/My Drive/cs236/fakes/cifarfake-c/*.png')\n",
        "#filelist = glob.glob('/content/drive/My Drive/cs236/fakes/acwgan-gp2/*.png')\n",
        "filelist = glob.glob('/content/drive/My Drive/cs236/reals/cifarreal2/*.png')\n",
        "print(type(filelist))\n",
        "print(len(filelist))\n",
        "imgs = [np.array(Image.open(fname)) for fname in filelist]\n",
        "print(type(imgs))\n",
        "print(imgs[0].shape)\n",
        "\n",
        "MODEL_DIR = '/tmp/imagenet'\n",
        "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
        "softmax = None\n",
        "\n",
        "# Call this function with list of images. Each of elements should be a \n",
        "# numpy array with values ranging from 0 to 255.\n",
        "def get_inception_score(images, splits=10):\n",
        "  assert(type(images) == list)\n",
        "  assert(type(images[0]) == np.ndarray)\n",
        "  assert(len(images[0].shape) == 3)\n",
        "  assert(np.max(images[0]) > 10)\n",
        "  assert(np.min(images[0]) >= 0.0)\n",
        "  inps = []\n",
        "  for img in images:\n",
        "    img = img.astype(np.float32)\n",
        "    inps.append(np.expand_dims(img, 0))\n",
        "  bs = 1\n",
        "  with tf.Session() as sess:\n",
        "    preds = []\n",
        "    n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n",
        "    for i in range(n_batches):\n",
        "        sys.stdout.write(\".\")\n",
        "        sys.stdout.flush()\n",
        "        inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n",
        "        inp = np.concatenate(inp, 0)\n",
        "        pred = sess.run(softmax, {'ExpandDims:0': inp})\n",
        "        preds.append(pred)\n",
        "    preds = np.concatenate(preds, 0)\n",
        "    scores = []\n",
        "    for i in range(splits):\n",
        "      part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
        "      kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "      kl = np.mean(np.sum(kl, 1))\n",
        "      scores.append(np.exp(kl))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "# This function is called automatically.\n",
        "def _init_inception():\n",
        "  global softmax\n",
        "  if not os.path.exists(MODEL_DIR):\n",
        "    os.makedirs(MODEL_DIR)\n",
        "  filename = DATA_URL.split('/')[-1]\n",
        "  filepath = os.path.join(MODEL_DIR, filename)\n",
        "  if not os.path.exists(filepath):\n",
        "    def _progress(count, block_size, total_size):\n",
        "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
        "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
        "      sys.stdout.flush()\n",
        "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
        "    print()\n",
        "    statinfo = os.stat(filepath)\n",
        "    print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "  tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)\n",
        "  with tf.gfile.FastGFile(os.path.join(\n",
        "      MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:\n",
        "    graph_def = tf.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "    _ = tf.import_graph_def(graph_def, name='')\n",
        "  # Works with an arbitrary minibatch size.\n",
        "  with tf.Session() as sess:\n",
        "    pool3 = sess.graph.get_tensor_by_name('pool_3:0')\n",
        "    ops = pool3.graph.get_operations()\n",
        "    for op_idx, op in enumerate(ops):\n",
        "        for o in op.outputs:\n",
        "            shape = o.get_shape()\n",
        "            shape = [s.value for s in shape]\n",
        "            new_shape = []\n",
        "            for j, s in enumerate(shape):\n",
        "                if s == 1 and j == 0:\n",
        "                    new_shape.append(None)\n",
        "                else:\n",
        "                    new_shape.append(s)\n",
        "            o.set_shape(tf.TensorShape(new_shape))\n",
        "    w = sess.graph.get_operation_by_name(\"softmax/logits/MatMul\").inputs[1]\n",
        "    logits = tf.matmul(tf.squeeze(pool3, [1, 2]), w)\n",
        "    softmax = tf.nn.softmax(logits)\n",
        "\n",
        "if softmax is None:\n",
        "  _init_inception()\n",
        "\n",
        "get_inception_score(imgs, splits=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<type 'list'>\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KenhXbPG3Nwv",
        "colab_type": "code",
        "outputId": "2192a544-dbe2-479f-ddf0-5a09fa10cb4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "from transformers import *\n",
        "import pdb\n",
        "from torch.nn.utils import weight_norm as wn\n",
        "from tqdm import tqdm\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "def bert_encoder():\n",
        "    return BERTEncoder()\n",
        "\n",
        "\n",
        "def class_embedding(n_classes, embedding_dim):\n",
        "    return nn.Embedding(n_classes, embedding_dim)\n",
        "\n",
        "\n",
        "def unconditional(n_classes, embedding_dim):\n",
        "    return nn.Embedding(n_classes, embedding_dim)\n",
        "\n",
        "\n",
        "class Embedder(nn.Module):\n",
        "    def __init__(self, embed_size):\n",
        "        super(Embedder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "    def forward(self, class_labels, captions):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class BERTEncoder(Embedder):\n",
        "    '''\n",
        "    pretrained model used to embed text to a 768 dimensional vector\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERTEncoder, self).__init__(embed_size=768)\n",
        "        self.pretrained_weights = 'bert-base-uncased'\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.pretrained_weights)\n",
        "        self.model = BertModel.from_pretrained(self.pretrained_weights)\n",
        "        self.max_len = 50\n",
        "\n",
        "    def tokenize(self, text_batch):\n",
        "        text_token_ids = [\n",
        "            torch.tensor(self.tokenizer.encode(string_, add_special_tokens=False, max_length=self.max_len)) for\n",
        "            string_ in text_batch]\n",
        "        padded_input = pad_sequence(text_token_ids, batch_first=True, padding_value=0)\n",
        "        return padded_input\n",
        "\n",
        "    def forward(self, class_labels, captions):\n",
        "        '''\n",
        "        :param class_labels : torch.LongTensor, class ids\n",
        "        :param list captions: list of strings, sentences to embed\n",
        "        :return: torch.tensor embeddings: embeddings of shape (batch_size,embed_size=768)\n",
        "        '''\n",
        "\n",
        "        padded_input = self.tokenize(captions)\n",
        "        device = list(self.parameters())[0].device\n",
        "        padded_input = padded_input.to(device)\n",
        "        # takes the mean of the last hidden states computed by the pre-trained BERT encoder and return it\n",
        "        return self.model(padded_input)[0].mean(dim=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "I1130 19:32:52.937437 140251756554112 file_utils.py:39] PyTorch version 1.3.1+cu100 available.\n",
            "/usr/local/lib/python2.7/dist-packages/sacremoses/truecase.py:26: UserWarning: You should really be using Python3!!! Tick tock, tick tock, https://pythonclock.org/\n",
            "  \"You should really be using Python3!!! \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRUlcnRy3NzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import collections\n",
        "import time\n",
        "import cPickle as pickle\n",
        "\n",
        "_since_beginning = collections.defaultdict(lambda: {})\n",
        "_since_last_flush = collections.defaultdict(lambda: {})\n",
        "\n",
        "_iter = [0]\n",
        "def tick():\n",
        "\t_iter[0] += 1\n",
        "\n",
        "def plot(name, value):\n",
        "\t_since_last_flush[name][_iter[0]] = value\n",
        "k = len(\"/content/drive/My drive/conwgan-gp/\")\n",
        "def flush():\n",
        "\tprints = []\n",
        "\n",
        "\tfor name, vals in _since_last_flush.items():\n",
        "\t\tname2 = name[k:];prints.append(\"{}\\t{}\".format(name2, np.mean(vals.values())))\n",
        "\t\t_since_beginning[name2].update(vals)\n",
        "\n",
        "\t\tx_vals = np.sort(_since_beginning[name2].keys())\n",
        "\t\ty_vals = [_since_beginning[name2][x] for x in x_vals]\n",
        "\n",
        "\t\tplt.clf()\n",
        "\t\tplt.plot(x_vals, y_vals)\n",
        "\t\tplt.xlabel('iteration')\n",
        "\t\tplt.ylabel(name2)\n",
        "\t\tplt.savefig(name+'.jpg')\n",
        "\n",
        "\tprint \"iter {}\\t{}\".format(_iter[0], \"\\t\".join(prints))\n",
        "\t_since_last_flush.clear()\n",
        "\n",
        "\twith open('log.pkl', 'wb') as f:\n",
        "\t\tpickle.dump(dict(_since_beginning), f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V3hGlxzf8uT",
        "colab_type": "text"
      },
      "source": [
        "# MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvKIwVEF3N1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch.autograd import grad\n",
        "import torch\n",
        "#Models taken and improved from https://github.com/igul222/improved_wgan_training/blob/master/gan_64x64.py\n",
        "DIM=64\n",
        "OUTPUT_DIM=64*64*3\n",
        "\n",
        "class MyConvo2d(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init = True,  stride = 1, bias = True):\n",
        "        super(MyConvo2d, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.padding = int((kernel_size - 1)/2)\n",
        "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=self.padding, bias = bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        return output\n",
        "\n",
        "class ConvMeanPool(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init = True):\n",
        "        super(ConvMeanPool, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        output = (output[:,:,::2,::2] + output[:,:,1::2,::2] + output[:,:,::2,1::2] + output[:,:,1::2,1::2]) / 4\n",
        "        return output\n",
        "\n",
        "class MeanPoolConv(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init = True):\n",
        "        super(MeanPoolConv, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = (output[:,:,::2,::2] + output[:,:,1::2,::2] + output[:,:,::2,1::2] + output[:,:,1::2,1::2]) / 4\n",
        "        output = self.conv(output)\n",
        "        return output\n",
        "\n",
        "class DepthToSpace(nn.Module):\n",
        "    def __init__(self, block_size):\n",
        "        super(DepthToSpace, self).__init__()\n",
        "        self.block_size = block_size\n",
        "        self.block_size_sq = block_size*block_size\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input.permute(0, 2, 3, 1)\n",
        "        (batch_size, input_height, input_width, input_depth) = output.size()\n",
        "        output_depth = int(input_depth / self.block_size_sq)\n",
        "        output_width = int(input_width * self.block_size)\n",
        "        output_height = int(input_height * self.block_size)\n",
        "        t_1 = output.reshape(batch_size, input_height, input_width, self.block_size_sq, output_depth)\n",
        "        spl = t_1.split(self.block_size, 3)\n",
        "        stacks = [t_t.reshape(batch_size,input_height,output_width,output_depth) for t_t in spl]\n",
        "        output = torch.stack(stacks,0).transpose(0,1).permute(0,2,1,3,4).reshape(batch_size,output_height,output_width,output_depth)\n",
        "        output = output.permute(0, 3, 1, 2)\n",
        "        return output\n",
        "\n",
        "\n",
        "class UpSampleConv(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, he_init = True, bias=True):\n",
        "        super(UpSampleConv, self).__init__()\n",
        "        self.he_init = he_init\n",
        "        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init, bias=bias)\n",
        "        self.depth_to_space = DepthToSpace(2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = torch.cat((output, output, output, output), 1)\n",
        "        output = self.depth_to_space(output)\n",
        "        output = self.conv(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, resample=None, hw=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.resample = resample\n",
        "        self.bn1 = None\n",
        "        self.bn2 = None\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.resample = resample\n",
        "        if resample == 'down':\n",
        "            self.bn1 = nn.LayerNorm([input_dim, hw, hw])\n",
        "            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n",
        "        elif resample == 'up':\n",
        "            self.bn1 = nn.BatchNorm2d(input_dim)\n",
        "            self.bn2 = nn.BatchNorm2d(output_dim)\n",
        "        elif resample == None:\n",
        "            #TODO: ????\n",
        "            self.bn1 = nn.BatchNorm2d(input_dim)\n",
        "            self.bn2 = nn.BatchNorm2d(output_dim)\n",
        "        else:\n",
        "            raise Exception('invalid resample value')\n",
        "\n",
        "        if resample == 'down':\n",
        "            self.conv_shortcut = MeanPoolConv(input_dim, output_dim, kernel_size = 1, he_init = False)\n",
        "            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n",
        "            self.conv_2 = ConvMeanPool(input_dim, output_dim, kernel_size = kernel_size)\n",
        "        elif resample == 'up':\n",
        "            self.conv_shortcut = UpSampleConv(input_dim, output_dim, kernel_size = 1, he_init = False)\n",
        "            self.conv_1 = UpSampleConv(input_dim, output_dim, kernel_size = kernel_size, bias = False)\n",
        "            self.conv_2 = MyConvo2d(output_dim, output_dim, kernel_size = kernel_size)\n",
        "        elif resample == None:\n",
        "            self.conv_shortcut = MyConvo2d(input_dim, output_dim, kernel_size = 1, he_init = False)\n",
        "            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n",
        "            self.conv_2 = MyConvo2d(input_dim, output_dim, kernel_size = kernel_size)\n",
        "        else:\n",
        "            raise Exception('invalid resample value')\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.input_dim == self.output_dim and self.resample == None:\n",
        "            shortcut = input\n",
        "        else:\n",
        "            shortcut = self.conv_shortcut(input)\n",
        "\n",
        "        output = input\n",
        "        if self.resample != 'down':\n",
        "            output = self.bn1(output)\n",
        "        output = self.relu1(output)\n",
        "        output = self.conv_1(output)\n",
        "        if self.resample != 'down':\n",
        "            output = self.bn2(output)\n",
        "        output = self.relu2(output)\n",
        "        output = self.conv_2(output)\n",
        "\n",
        "        return shortcut + output\n",
        "\n",
        "class ReLULayer(nn.Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(ReLULayer, self).__init__()\n",
        "        self.n_in = n_in\n",
        "        self.n_out = n_out\n",
        "        self.linear = nn.Linear(n_in, n_out)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.linear(input)\n",
        "        output = self.relu(output)\n",
        "        return output\n",
        "\n",
        "class FCGenerator(nn.Module):\n",
        "    def __init__(self, FC_DIM=512):\n",
        "        super(FCGenerator, self).__init__()\n",
        "        self.relulayer1 = ReLULayer(128, FC_DIM)\n",
        "        self.relulayer2 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.relulayer3 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.relulayer4 = ReLULayer(FC_DIM, FC_DIM)\n",
        "        self.linear = nn.Linear(FC_DIM, OUTPUT_DIM)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.relulayer1(input)\n",
        "        output = self.relulayer2(output)\n",
        "        output = self.relulayer3(output)\n",
        "        output = self.relulayer4(output)\n",
        "        output = self.linear(output)\n",
        "        output = self.tanh(output)\n",
        "        return output\n",
        "\n",
        "class GoodGenerator(nn.Module):\n",
        "    def __init__(self, dim=DIM,output_dim=OUTPUT_DIM):\n",
        "        super(GoodGenerator, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "\n",
        "        self.ln1 = nn.Linear(128, 4*4*8*self.dim)\n",
        "        #self.rb1 = ResidualBlock(8*self.dim, 8*self.dim, 3, resample = None)\n",
        "        self.rb2 = ResidualBlock(8*self.dim, 4*self.dim, 3, resample = 'up')\n",
        "        self.rb3 = ResidualBlock(4*self.dim, 2*self.dim, 3, resample = 'up')\n",
        "        self.rb4 = ResidualBlock(2*self.dim, 1*self.dim, 3, resample = 'up')\n",
        "        self.bn  = nn.BatchNorm2d(self.dim)\n",
        "\n",
        "        self.conv1 = MyConvo2d(1*self.dim, 3, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.ln1(input.contiguous())\n",
        "        output = output.view(-1, 8*self.dim, 4, 4)\n",
        "        #output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "\n",
        "        output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.conv1(output)\n",
        "        output = self.tanh(output)\n",
        "        output = output.view(-1, OUTPUT_DIM)\n",
        "        return output\n",
        "\n",
        "class GoodDiscriminator(nn.Module):\n",
        "    def __init__(self, dim=DIM, num_class=2):\n",
        "        super(GoodDiscriminator, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.num_class = num_class\n",
        "        self.conv1 = MyConvo2d(3, self.dim, 3, he_init = False)\n",
        "        self.rb1 = ResidualBlock(self.dim, 2*self.dim, 3, resample = 'down', hw=DIM)\n",
        "        self.rb2 = ResidualBlock(2*self.dim, 4*self.dim, 3, resample = 'down', hw=int(DIM/2))\n",
        "        self.rb3 = ResidualBlock(4*self.dim, 8*self.dim, 3, resample = 'down', hw=int(DIM/4))\n",
        "        #self.rb4 = ResidualBlock(8*self.dim, 8*self.dim, 3, resample = 'down', hw=int(DIM/8))\n",
        "        self.ln1 = nn.Linear(4*4*8*self.dim, 1)\n",
        "\n",
        "        self.ln2 = nn.Linear(4*4*8*self.dim, self.num_class)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input.contiguous()\n",
        "        output = output.view(-1, 3, DIM, DIM)\n",
        "        output = self.conv1(output)\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        #output = self.rb4(output)\n",
        "        output = output.view(-1, 4*4*8*self.dim)\n",
        "        output_wgan = self.ln1(output)\n",
        "        output_wgan = output_wgan.view(-1)\n",
        "        output_congan = self.ln2(output)\n",
        "        return output_wgan, output_congan\n",
        "\n",
        "  class Classifier(nn.Module):\n",
        "    def __init__(self, dim=DIM):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.conv1 = MyConvo2d(3, self.dim, 3, he_init = False)\n",
        "        self.rb1 = ResidualBlock(self.dim, 2*self.dim, 3, resample = 'down', hw=DIM)\n",
        "        self.rb2 = ResidualBlock(2*self.dim, 4*self.dim, 3, resample = 'down', hw=int(DIM/2))\n",
        "        self.rb3 = ResidualBlock(4*self.dim, 8*self.dim, 3, resample = 'down', hw=int(DIM/4))\n",
        "        #self.rb4 = ResidualBlock(8*self.dim, 8*self.dim, 3, resample = 'down', hw=int(DIM/8))\n",
        "        self.ln1 = nn.Linear(4*4*8*self.dim + 10, 1)\n",
        "\n",
        "        self.sigmoid  = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        output = input.contiguous()\n",
        "        output = output.view(-1, 3, DIM, DIM)\n",
        "        output = self.conv1(output)\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        #output = self.rb4(output)\n",
        "        output = output.view(-1, 4*4*8*self.dim)\n",
        "        output = torch.cat((output, label), 1)\n",
        "        output = self.ln1(output)\n",
        "        \n",
        "        realfake = self.sigmoid(output)\n",
        "        return realfake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUzgIfe6gBPD",
        "colab_type": "text"
      },
      "source": [
        "# TRAIN ACGAN/ACWGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MwKgvLs3N4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "#Models taken and improved from https://github.com/igul222/improved_wgan_training/blob/master/gan_64x64.py\n",
        "import time\n",
        "import functools\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "#import sklearn.datasets\n",
        "\n",
        "#import libs as lib\n",
        "#import libs.plot\n",
        "#from tensorboardX import SummaryWriter\n",
        "\n",
        "import pdb\n",
        "#import gpustat\n",
        "\n",
        "#from models.conwgan import *\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch import autograd\n",
        "from torch import optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.autograd import grad\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import torch.nn.init as init\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/'\n",
        "\n",
        "cifar_text_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "encoder = BERTEncoder()\n",
        "\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "load_model = False\n",
        "START_ITER = 0 \n",
        "OUTPUT_PATH = '/content/drive/My Drive/conwgan-gp/'\n",
        "\n",
        "\n",
        "DIM = 32 # Model dimensionality\n",
        "CRITIC_ITERS = 5 # How many iterations to train the critic for\n",
        "GENER_ITERS = 1\n",
        "N_GPUS = 1 # Number of GPUs\n",
        "BATCH_SIZE = 100# Batch size. Must be a multiple of N_GPUS\n",
        "END_ITER = 100000 # How many iterations to train for\n",
        "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
        "OUTPUT_DIM = 32*32*3 # Number of pixels in each iamge\n",
        "ACGAN_SCALE = 1. # How to scale the critic's ACGAN loss relative to WGAN loss\n",
        "ACGAN_SCALE_G = 1. # How to scale generator's ACGAN loss relative to WGAN loss\n",
        "\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, MyConvo2d): \n",
        "        if m.conv.weight is not None:\n",
        "            if m.he_init:\n",
        "                init.kaiming_uniform_(m.conv.weight)\n",
        "            else:\n",
        "                init.xavier_uniform_(m.conv.weight)\n",
        "        if m.conv.bias is not None:\n",
        "            init.constant_(m.conv.bias, 0.0)\n",
        "    if isinstance(m, nn.Linear):\n",
        "        if m.weight is not None:\n",
        "            init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0.0)\n",
        "\n",
        "def load_data(path_to_folder, classes):\n",
        "    dataset = datasets.CIFAR10(\n",
        "          root=path_to_folder, download=True,\n",
        "          transform=transforms.Compose([\n",
        "              transforms.Scale(32),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "          ]))\n",
        "    dataset_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=5, drop_last=True, pin_memory=True)\n",
        "    return dataset_loader\n",
        "\n",
        "def calc_gradient_penalty(netD, real_data, fake_data):\n",
        "    alpha = torch.rand(BATCH_SIZE, 1)\n",
        "    alpha = alpha.expand(BATCH_SIZE, int(real_data.nelement()/BATCH_SIZE)).contiguous()\n",
        "    alpha = alpha.view(BATCH_SIZE, 3, 32, 32)\n",
        "    alpha = alpha.to(device)\n",
        "\n",
        "    fake_data = fake_data.view(BATCH_SIZE, 3, 32, 32)\n",
        "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
        "\n",
        "    interpolates = interpolates.to(device)\n",
        "    interpolates.requires_grad_(True)   \n",
        "\n",
        "    disc_interpolates, _ = netD(interpolates)\n",
        "\n",
        "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)                              \n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
        "    return gradient_penalty\n",
        "\n",
        "def generate_image(netG, noise=None):\n",
        "    if noise is None:\n",
        "        #rand_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "        rand_label = np.repeat(np.arange(10), 100//10)\n",
        "        noise = gen_rand_noise_with_label(rand_label)\n",
        "    with torch.no_grad():\n",
        "        noisev = noise\n",
        "    samples = netG(noisev)\n",
        "    samples = samples.view(BATCH_SIZE, 3, 32, 32)\n",
        "\n",
        "    samples = samples * 0.5 + 0.5\n",
        "\n",
        "    return samples\n",
        "\n",
        "def gen_rand_noise_with_label(label=None):\n",
        "    if label is None:\n",
        "        label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "    noise = np.random.normal(0, 1, (BATCH_SIZE, 128))\n",
        "\n",
        "    captions = [cifar_text_labels[per_label] for per_label in label]\n",
        "    embedding = encoder(label, captions)\n",
        "    embedding = embedding.detach().numpy()\n",
        "\n",
        "    noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = embedding[:, :10]\n",
        "\n",
        "    noise = torch.from_numpy(noise).float()\n",
        "    noise = noise.to(device)\n",
        "\n",
        "    return noise\n",
        "\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "fixed_label = []\n",
        "for c in range(BATCH_SIZE):\n",
        "    fixed_label.append(c%NUM_CLASSES)\n",
        "fixed_noise = gen_rand_noise_with_label(fixed_label)\n",
        "\n",
        "if load_model:\n",
        "    aG = torch.load(OUTPUT_PATH + \"generator\" + str(START_ITER) + \".pt\")\n",
        "\n",
        "    aD = torch.load(OUTPUT_PATH + \"discriminator\" + str(START_ITER) + \".pt\")\n",
        "    \n",
        "else:\n",
        "    aG = GoodGenerator(DIM,OUTPUT_DIM)\n",
        "    aD = GoodDiscriminator(DIM, NUM_CLASSES)\n",
        "    \n",
        "    aG.apply(weights_init)\n",
        "    aD.apply(weights_init)\n",
        "\n",
        "LR = 1e-4\n",
        "optimizer_g = torch.optim.Adam(aG.parameters(), lr=LR, betas=(0,0.9))\n",
        "optimizer_d = torch.optim.Adam(aD.parameters(), lr=LR, betas=(0,0.9))\n",
        "\n",
        "aux_criterion = nn.CrossEntropyLoss() # nn.NLLLoss()\n",
        "\n",
        "one = torch.FloatTensor([1])\n",
        "mone = one * -1\n",
        "aG = aG.to(device)\n",
        "aD = aD.to(device)\n",
        "one = one.to(device)\n",
        "mone = mone.to(device)\n",
        "\n",
        "#Reference: https://github.com/caogang/wgan-gp/blob/master/gan_cifar10.py\n",
        "\n",
        "dataloader = load_data(DATA_DIR, cifar_text_labels)\n",
        "dataiter = iter(dataloader)\n",
        "for iteration in range(START_ITER+1, END_ITER):\n",
        "    start_time = time.time()\n",
        "    start = timer()\n",
        "    #---------------------TRAIN C------------------------\n",
        "    '''\n",
        "    for p in aC.parameters():\n",
        "        p.requires_grad_(True)\n",
        "    for l in range(CITER):\n",
        "      f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "      noise = gen_rand_noise_with_label(f_label)\n",
        "      with torch.no_grad():\n",
        "          noisev = noise  # totally freeze G, training D\n",
        "      fake_data = aG(noisev).detach()\n",
        "      batch = next(dataiter, None)\n",
        "      if batch is None:\n",
        "          dataiter = iter(dataloader)\n",
        "          batch = dataiter.next()\n",
        "      real_data = batch[0] #batch[1] contains labels\n",
        "      real_data.requires_grad_(True)\n",
        "\n",
        "      real_data = real_data.to(device)\n",
        "      p_fake = aC(fake_data)\n",
        "      c_err_fake = c_criterion(p_fake, zone)\n",
        "      p_real = aC(real_data)\n",
        "      c_err_real = c_criterion(p_real, one)\n",
        "      k = c_err_real + c_err_fake\n",
        "      (c_err_real + c_err_fake).backward()\n",
        "      optimizer_c.step()\n",
        "    for p in aC.parameters():\n",
        "        p.requires_grad_(False)\n",
        "    '''\n",
        "    #---------------------TRAIN G------------------------\n",
        "    for p in aD.parameters():\n",
        "        p.requires_grad_(False) \n",
        "\n",
        "    gen_cost = None\n",
        "    for i in range(GENER_ITERS):\n",
        "        aG.zero_grad()\n",
        "        f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "        noise = gen_rand_noise_with_label(f_label)\n",
        "        noise.requires_grad_(True)\n",
        "        fake_data = aG(noise)\n",
        "        gen_cost, gen_aux_output = aD(fake_data)\n",
        "        '''\n",
        "        probs = aC(fake_data)\n",
        "        #print(torch.max(probs))\n",
        "        sniw = 1\n",
        "        if iteration > 2005:\n",
        "          iw = probs / (1 - probs)\n",
        "          iw = iw.clamp(0.01, 0.99)\n",
        "          sum_iw = torch.sum(iw)\n",
        "          sniw = iw / sum_iw\n",
        "        '''\n",
        "\n",
        "        aux_label = torch.from_numpy(f_label).long()\n",
        "        aux_label = aux_label.to(device)\n",
        "        aux_errG = aux_criterion(gen_aux_output, aux_label).mean()\n",
        "        gen_cost = -gen_cost.mean()\n",
        "        g_cost = ACGAN_SCALE_G*aux_errG + gen_cost\n",
        "        g_cost.backward()\n",
        "    \n",
        "    optimizer_g.step()\n",
        "    #---------------------TRAIN D------------------------\n",
        "    for p in aD.parameters():\n",
        "        p.requires_grad_(True)  \n",
        "    for i in range(CRITIC_ITERS):\n",
        "        \n",
        "        start = timer()\n",
        "        aD.zero_grad()\n",
        "\n",
        "        f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "        noise = gen_rand_noise_with_label(f_label)\n",
        "        with torch.no_grad():\n",
        "            noisev = noise\n",
        "        fake_data = aG(noisev).detach()\n",
        "        batch = next(dataiter, None)\n",
        "        if batch is None:\n",
        "            dataiter = iter(dataloader)\n",
        "            batch = dataiter.next()\n",
        "        real_data = batch[0]\n",
        "        real_data.requires_grad_(True)\n",
        "        real_label = batch[1]\n",
        "\n",
        "        #start = timer()\n",
        "        real_data = real_data.to(device)\n",
        "        real_label = real_label.to(device)\n",
        "\n",
        "        # train with real data\n",
        "        disc_real, aux_output = aD(real_data)\n",
        "        aux_errD_real = aux_criterion(aux_output, real_label)\n",
        "        errD_real = aux_errD_real.mean()\n",
        "        disc_real = disc_real.mean()\n",
        "\n",
        "\n",
        "        # train with fake data\n",
        "        disc_fake, aux_output = aD(fake_data)\n",
        "        disc_fake = disc_fake.mean()\n",
        "\n",
        "        gradient_penalty = calc_gradient_penalty(aD, real_data, fake_data)\n",
        "        #aux_errD_fake = aux_criterion(aux_output, f_label)\n",
        "        #errD_fake = aux_errD_fake.mean()\n",
        "        disc_cost = disc_fake - disc_real + gradient_penalty\n",
        "        disc_acgan = errD_real #+ errD_fake\n",
        "        (disc_cost + ACGAN_SCALE*disc_acgan).backward()\n",
        "        w_dist = disc_fake  - disc_real\n",
        "        optimizer_d.step()\n",
        "        #for p in aD.parameters():\n",
        "        #    p.data.clamp_(-0.01, 0.01)\n",
        "        #------------------VISUALIZATION----------\n",
        "        if i == CRITIC_ITERS-1:\n",
        "            plot(OUTPUT_PATH + 'Disc Cost', disc_cost.cpu().data.numpy())\n",
        "            plot(OUTPUT_PATH + 'AC Disc Cost', disc_acgan.cpu().data.numpy())\n",
        "\n",
        "            plot(OUTPUT_PATH + 'time', time.time() - start_time)\n",
        "            plot(OUTPUT_PATH + 'Gen Cost', gen_cost.cpu().data.numpy())\n",
        "            plot(OUTPUT_PATH + 'AC Gen Cost', aux_errG.cpu().data.numpy())\n",
        "            plot(OUTPUT_PATH + 'wasserstein distance', w_dist.cpu().data.numpy())\n",
        "    if iteration % 100==99:\n",
        "        gen_images = generate_image(aG, fixed_noise)\n",
        "        torchvision.utils.save_image(gen_images, OUTPUT_PATH + 'samples_{}.png'.format(iteration), nrow=10, padding=2)\n",
        "#----------------------Save model----------------------\n",
        "        torch.save(aG, OUTPUT_PATH + \"generator\" + str(iteration) + \".pt\")\n",
        "        torch.save(aD, OUTPUT_PATH + \"discriminator\" + str(iteration) + \".pt\")\n",
        "    if (iteration < 50) or (iteration % 100 == 99):\n",
        "        flush()\n",
        "    tick()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecO8-HC-gFY9",
        "colab_type": "text"
      },
      "source": [
        "# TRAIN CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mFIFMNYN9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "\n",
        "import time\n",
        "import functools\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "#import sklearn.datasets\n",
        "\n",
        "#import libs as lib\n",
        "#import libs.plot\n",
        "#from tensorboardX import SummaryWriter\n",
        "\n",
        "import pdb\n",
        "#import gpustat\n",
        "\n",
        "#from models.conwgan import *\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch import autograd\n",
        "from torch import optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.autograd import grad\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import torch.nn.init as init\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/'\n",
        "cifar_text_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "encoder = BERTEncoder()\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "\n",
        "START_ITER = 9699 # starting iteration \n",
        "OUTPUT_PATH = '/content/drive/My Drive/conwgan-iw/'\n",
        "\n",
        "DIM = 32 # Model dimensionality\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, MyConvo2d): \n",
        "        if m.conv.weight is not None:\n",
        "            if m.he_init:\n",
        "                init.kaiming_uniform_(m.conv.weight)\n",
        "            else:\n",
        "                init.xavier_uniform_(m.conv.weight)\n",
        "        if m.conv.bias is not None:\n",
        "            init.constant_(m.conv.bias, 0.0)\n",
        "    if isinstance(m, nn.Linear):\n",
        "        if m.weight is not None:\n",
        "            init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0.0)\n",
        "\n",
        "def load_data(path_to_folder, classes):\n",
        "\n",
        "    dataset = datasets.CIFAR10(\n",
        "          root=path_to_folder, download=True,\n",
        "          transform=transforms.Compose([\n",
        "              transforms.Scale(32),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "          ]))\n",
        "    dataset_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=5, drop_last=True, pin_memory=True)\n",
        "    return dataset_loader\n",
        "\n",
        "\n",
        "\n",
        "def generate_image(netG, noise=None):\n",
        "    if noise is None:\n",
        "        #rand_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "        rand_label = np.repeat(np.arange(10), 100//10)\n",
        "        noise = gen_rand_noise_with_label(rand_label)\n",
        "    with torch.no_grad():\n",
        "        noisev = noise\n",
        "    samples = netG(noisev)\n",
        "    samples = samples.view(BATCH_SIZE, 3, 32, 32)\n",
        "\n",
        "    samples = samples * 0.5 + 0.5\n",
        "\n",
        "    return samples\n",
        "\n",
        "def gen_rand_noise_with_label(label=None):\n",
        "    if label is None:\n",
        "        label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "    noise = np.random.normal(0, 1, (BATCH_SIZE, 128))\n",
        "\n",
        "    captions = [cifar_text_labels[per_label] for per_label in label]\n",
        "    embedding = encoder(label, captions)\n",
        "    embedding = embedding.detach().numpy()\n",
        "\n",
        "    noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = embedding[:, :10]\n",
        "\n",
        "    noise = torch.from_numpy(noise).float()\n",
        "    noise = noise.to(device)\n",
        "\n",
        "    return noise\n",
        "\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "\n",
        "aG = torch.load(OUTPUT_PATH + \"generator\" + str(START_ITER) + \".pt\")\n",
        "aC = Classifier(DIM)\n",
        "aC.apply(weights_init)\n",
        "LR = 1e-4\n",
        "optimizer_c = torch.optim.Adam(aC.parameters(), lr=LR, betas=(0,0.9))\n",
        "\n",
        "#aux_criterion = nn.CrossEntropyLoss() # nn.NLLLoss()\n",
        "\n",
        "c_criterion = nn.BCELoss()#nn.CrossEntropyLoss()#nn.BCELoss()\n",
        "\n",
        "one = torch.FloatTensor([1])\n",
        "one = torch.ones([100, 1], dtype=torch.float32)\n",
        "zone = torch.zeros([100, 1], dtype = torch.float32)\n",
        "mone = one * -1\n",
        "aG = aG.to(device)\n",
        "#aD = aD.to(device)\n",
        "aC = aC.to(device)\n",
        "one = one.to(device)\n",
        "mone = mone.to(device)\n",
        "zone = zone.to(device)\n",
        "\n",
        "dataloader = load_data(DATA_DIR, TRAINING_CLASS)\n",
        "dataiter = iter(dataloader)\n",
        "\n",
        "for iteration in range(1, 5000):\n",
        "    start_time = time.time()\n",
        "    for p in aC.parameters():\n",
        "        p.requires_grad_(True) \n",
        "    f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "    noise = gen_rand_noise_with_label(f_label)\n",
        "    with torch.no_grad():\n",
        "        noisev = noise \n",
        "    fake_data = aG(noisev).detach()\n",
        "    batch = next(dataiter, None)\n",
        "    if batch is None:\n",
        "        dataiter = iter(dataloader)\n",
        "        batch = dataiter.next()\n",
        "    real_data = batch[0]\n",
        "    real_data = real_data.to(device)\n",
        "    real_labels = batch[1].to(device)\n",
        "    y = torch.LongTensor(f_label).to(device)\n",
        "    o_h = torch.nn.functional.one_hot(y, num_classes=10).type(torch.FloatTensor).to(device)\n",
        "    p_fake = aC(fake_data, o_h)\n",
        "    \n",
        "    c_err_fake = c_criterion(p_fake, zone)\n",
        "    o_h = torch.nn.functional.one_hot(real_labels, num_classes=10).type(torch.FloatTensor).to(device)\n",
        "    p_real = aC(real_data, o_h)\n",
        "    \n",
        "    c_err_real = c_criterion(p_real, one)\n",
        "    k = (c_err_real + c_err_fake)\n",
        "    k.backward()\n",
        "    optimizer_c.step()\n",
        "    torch.save(aC, OUTPUT_PATH + \"classifier10b.pt\")\n",
        "print(\"DONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUgjUq7dp7S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "\n",
        "import time\n",
        "import functools\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "#import sklearn.datasets\n",
        "\n",
        "#import libs as lib\n",
        "#import libs.plot\n",
        "#from tensorboardX import SummaryWriter\n",
        "\n",
        "import pdb\n",
        "#import gpustat\n",
        "\n",
        "#from models.conwgan import *\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch import autograd\n",
        "from torch import optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.autograd import grad\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import torch.nn.init as init\n",
        "\n",
        "DATA_DIR = '/content/drive/My Drive/'\n",
        "\n",
        "\n",
        "cifar_text_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "encoder = BERTEncoder()\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "START_ITER = 9699 # starting iteration \n",
        "\n",
        "\n",
        "\n",
        "N_GPUS = 1 # Number of GPUs\n",
        "BATCH_SIZE = 1000# Batch size. Must be a multiple of N_GPUS\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, MyConvo2d): \n",
        "        if m.conv.weight is not None:\n",
        "            if m.he_init:\n",
        "                init.kaiming_uniform_(m.conv.weight)\n",
        "            else:\n",
        "                init.xavier_uniform_(m.conv.weight)\n",
        "        if m.conv.bias is not None:\n",
        "            init.constant_(m.conv.bias, 0.0)\n",
        "    if isinstance(m, nn.Linear):\n",
        "        if m.weight is not None:\n",
        "            init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0.0)\n",
        "\n",
        "def load_data(path_to_folder, classes):\n",
        "\n",
        "\n",
        "    dataset = datasets.CIFAR10(\n",
        "          root=path_to_folder, download=True,\n",
        "          transform=transforms.Compose([\n",
        "              transforms.Scale(32),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "          ]))\n",
        "    dataset_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=5, drop_last=True, pin_memory=True)\n",
        "    return dataset_loader\n",
        "\n",
        "\n",
        "\n",
        "def generate_image(netG, noise=None):\n",
        "    if noise is None:\n",
        "        #rand_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "        rand_label = np.repeat(np.arange(10), 100//10)\n",
        "        noise = gen_rand_noise_with_label(rand_label)\n",
        "    with torch.no_grad():\n",
        "        noisev = noise\n",
        "    samples = netG(noisev)\n",
        "    samples = samples.view(BATCH_SIZE, 3, 32, 32)\n",
        "\n",
        "    samples = samples * 0.5 + 0.5\n",
        "\n",
        "    return samples\n",
        "\n",
        "label = np.arange(10)\n",
        "captions = [cifar_text_labels[per_label] for per_label in label]\n",
        "embedding = encoder(label, captions)\n",
        "embedding = embedding.detach().numpy()\n",
        "embedding = embedding[:, :10]\n",
        "\n",
        "def gen_rand_noise_with_label(label=None):\n",
        "    if label is None:\n",
        "        label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "    #attach label into noise\n",
        "    noise = np.random.normal(0, 1, (BATCH_SIZE, 128))\n",
        "\n",
        "    captions = [cifar_text_labels[per_label] for per_label in label]\n",
        "    embedding = encoder(label, captions)\n",
        "    embedding = embedding.detach().numpy()\n",
        "\n",
        "    noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = embedding[:, :10]\n",
        "\n",
        "    noise = torch.from_numpy(noise).float()\n",
        "    noise = noise.to(device)\n",
        "\n",
        "    return noise\n",
        "\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "\n",
        "aG = torch.load(OUTPUT_PATH + \"generator\" + str(START_ITER) + \".pt\")\n",
        "aC = torch.load(OUTPUT_PATH + \"classifier10b.pt\")\n",
        "\n",
        "\n",
        "for iteration in range(1, 15):\n",
        "    start_time = time.time()\n",
        "    #for p in aD.parameters():\n",
        "    #    p.requires_grad_(False)  # freeze D\n",
        "\n",
        "    for p in aC.parameters():\n",
        "        p.requires_grad_(True)  # freeze C\n",
        "    if iteration >= 0:\n",
        "          for l in range(1):\n",
        "            #print l\n",
        "            f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "            noise = gen_rand_noise_with_label(f_label)\n",
        "            with torch.no_grad():\n",
        "                noisev = noise  # totally freeze G, training D\n",
        "            fake_data = aG(noisev).detach()\n",
        "            #end = timer(); #print(f'---gen G elapsed time: {end-start}')\n",
        "            #start = timer()\n",
        "            batch = next(dataiter, None)\n",
        "            if batch is None:\n",
        "                dataiter = iter(dataloader)\n",
        "                batch = dataiter.next()\n",
        "            real_data = batch[0] #batch[1] contains labels\n",
        "            #print(\"r_label\" + str(r_label))\n",
        "            #end = timer(); #print(f'---load real imgs elapsed time: {end-start}')\n",
        "\n",
        "            #start = timer()\n",
        "            real_data = real_data.to(device)\n",
        "            real_labels = batch[1].to(device)\n",
        "            y = torch.LongTensor(f_label).to(device)\n",
        "            o_h = torch.nn.functional.one_hot(y, num_classes=10).type(torch.FloatTensor).to(device)\n",
        "            p_fake = aC(fake_data, o_h)\n",
        "            etheta = p_fake.mean()\n",
        "            elogtheta = torch.log(p_fake).mean()\n",
        "            print(\"E_t(w): \", etheta)\n",
        "            print(\"E_t(log(w)): \", elogtheta)\n",
        "            \n",
        "            #c_err_fake = c_criterion(p_fake, zone)\n",
        "            o_h = torch.nn.functional.one_hot(real_labels, num_classes=10).type(torch.FloatTensor).to(device)\n",
        "            p_real = aC(real_data, o_h)\n",
        "            ereal = p_real.mean()\n",
        "            elogreal = torch.log(p_real).mean()\n",
        "            print(\"E_r(w): \", ereal)\n",
        "            print(\"E_r(log(w)): \", elogreal)\n",
        "            #print(\"REAL PRED\")\n",
        "            #print(p_real[0:5])\n",
        "            #print(real_labels[0:5])\n",
        "            \n",
        "            #c_err_real = c_criterion(p_real, one)\n",
        "            #k = (c_err_real + c_err_fake)\n",
        "            #k.backward()\n",
        "            #print(k.shape)\n",
        "            #optimizer_c.step()\n",
        "            #if l==(CITER - 1):QDZ\n",
        "            #  print(k)\n",
        "          #print(iteration)\n",
        "print(\"DONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo7k6wiZgKrL",
        "colab_type": "text"
      },
      "source": [
        "# SAMPLING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO3VHnbAp7Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "aG = torch.load(OUTPUT_PATH + \"generator\" + str(START_ITER) + \".pt\")\n",
        "aC = torch.load(OUTPUT_PATH + \"classifier10b.pt\")\n",
        "cifar_text_labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "coarse_labels = [\"plane\", \"car\", \"bird\", \"pet\", \"animal\", \"pet\", \"frog\", \"animal\", \"boat\", \"car\"]\n",
        "def gen_rand_noise_with_coarse_label(label=None):\n",
        "    if label is None:\n",
        "        label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
        "    #attach label into noise\n",
        "    noise = np.random.normal(0, 1, (BATCH_SIZE, 128))\n",
        "    captions = [coarse_labels[per_label] for per_label in label]\n",
        "    embedding = encoder(label, captions)\n",
        "    embedding = embedding.detach().numpy()\n",
        "\n",
        "    #eval_noise_[np.arange(opt.batchSize), :opt.embed_size] = embedding[:, :opt.embed_size]\n",
        "    #prefix = np.zeros((BATCH_SIZE, NUM_CLASSES))\n",
        "    #prefix[np.arange(BATCH_SIZE), label] = 1\n",
        "    #noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = prefix[np.arange(BATCH_SIZE)]\n",
        "    #embedd = np.zeros((100, 10))\n",
        "    #for i in range(100):\n",
        "    #  embedd[i] = embedding[label[i]]\n",
        "    #noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = embedd\n",
        "    noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = embedding[:, :10]\n",
        "\n",
        "    noise = torch.from_numpy(noise).float()\n",
        "    noise = noise.to(device)\n",
        "\n",
        "    return noise\n",
        "j = 10000\n",
        "k = 0\n",
        "print(\"GENNING\")\n",
        "while True:\n",
        "  #f_label = np.repeat(np.arange(10), 1000//10)\n",
        "  #noise = gen_rand_noise_with_label(f_label)\n",
        "  #noise = gen_rand_noise_with_coarse_label(f_label)\n",
        "  #fake = torch.zeros(100, 3, 32, 32)\n",
        "  #fakes.destroy()\n",
        "  #torch.cuda.empty_cache() \n",
        "  #fakes = generate_image(aG, noise=noise)\n",
        "  for i in range(10):\n",
        "    f_label = np.repeat(i, 10)\n",
        "    #noise = gen_rand_noise_with_label(f_label)\n",
        "    noise = gen_rand_noise_with_coarse_label(f_label)\n",
        "    samples = generate_image(aG, noise=noise)\n",
        "    #s = 100 * i\n",
        "    #e = 100 * (i + 1)\n",
        "    #samples = fakes[s:e,:,:,:]\n",
        "    #probs = aC(samples)\n",
        "    y = torch.LongTensor(f_label).to(device)\n",
        "    o_h = torch.nn.functional.one_hot(y, num_classes=10).type(torch.FloatTensor).to(device)\n",
        "    #y = \n",
        "    probs = aC(samples, o_h)[:,0]\n",
        "    #print(probs.shape)\n",
        "    #_, probs = aD(samples)\n",
        "    #probs = probs[:, i]\n",
        "    #print(probs.shape)\n",
        "    #probs = probs.clamp(0.001, 0.999)\n",
        "    iw = probs/(1-probs)\n",
        "    lfiw = iw / iw.sum()\n",
        "    #best = torch.argmax(torch.multinomial(lfiw, 10).sample())\n",
        "    best = np.random.multinomial(1, lfiw.cpu().detach().numpy(), size=1).argmax()\n",
        "    #print(lfiw)\n",
        "    #print(best)\n",
        "    vutils.save_image(samples[best,:,:,:], '/content/drive/My Drive/cs236/fakes/acwgan-gp-c-iw/real_samples%d.png' %  (k))\n",
        "    k += 1\n",
        "    #best = torch.argsort(probs, descending = True)\n",
        "    #tops = iw[best]\n",
        "    #print(tops[0:10])\n",
        "\n",
        "    #fs = 10*i\n",
        "    #fe = 10*(i + 1)\n",
        "    #print(probs[best[0:10]])\n",
        "    #top10 = samples[best[0:10], :, :, :]\n",
        "    #print(probs[best])\n",
        "    #print(top10.shape)\n",
        "    #fake[fs:fe, :, :, :] = top10\n",
        "  #filename = '/content/drive/My Drive/cs236/acgan-gp-Biw.png'\n",
        "  #vutils.save_image(\n",
        "  #    fake,\n",
        "  #    filename,\n",
        "  #    nrow = 10,\n",
        "  #    padding = 2\n",
        "  #)\n",
        "  #for m,im in enumerate(fake):\n",
        "  #  #vutils.save_image(im, '/content/drive/My Drive/cs236/fakes/10platent/10pfakes/real_samples%d.png' %  (m + k))\n",
        "  #  vutils.save_image(im, '/content/drive/My Drive/cs236/fakes/acwgan-gp-Biw/real_samples%d.png' %  (m + k))\n",
        "  #k += 100\n",
        "  print(k)\n",
        "  if k >= j:\n",
        "    break\n",
        "print(\"DONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}